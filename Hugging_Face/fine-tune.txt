pip install huggingface_hub
huggingface-cli login
huggingface-cli repo create Wav2Vec2-Large-XLSR-53-Portuguese

curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
sudo apt-get install git-lfs

git clone https://huggingface.co/Rubens/Wav2Vec2-Large-XLSR-53-Portuguese
open folder Wav2Vec2-Large-XLSR-53-Portuguese
cd folder
gsutil cp -r gs://hugging-XXX/checkpoint-1000-XXX/* ./

update train/evaluate code pt + model at Readme.md

select:
preprocessor_config.json
special_tokens_map.json
tokenizer_config.json
vocab.json
config.json
pytorch_model.bin

git add .
git commit -m "commit from $USER"
git push

-------------------------------------------------------------------------------------------
Nan loss:
If you encounter nan it means some of your audio files have a problem. Mostly it becomes much more problematic when you have a large audio with a very small text associated to it or a very small audio with a very large text associated to it.
Wav2vec2 has inbuilt loss scale that can handle nan loss. The loss scale starts from 128 and goes down by a factor of 2 every time there is a overflow detected to a minimum of 0.06
Augmentation:
You can start with augmentations on pace, pitch, volume. You can also add white/pink noise to make model more robust. But there are instances where I have observed that if the training data (text data) is repeated across sentences i.e. across various speakers the model tends to overfit.
Training/Validation Loss:
I have seen training and validation loss have less correlation with WER. It is quite possible that the validation loss stays constant while the validation WER keeps on decreasing.
Audio Length:
I always make sure that the input wav length during training is not more than 480000 frames, at 16000 sample rate it comes out to be 30 seconds. For XLSR it is a mandatory rule for me because I train on 16GB X 16 V-100's.
Parameters:
The XLSR has close to 300M parameters, so finetuning a model with XLSR is not easy in terms of compute. There is a parameter called max_tokens. If you set max_tokens to 480000 it means you are allowing a maximum of 30 seconds audio in one batch and that is the minimum batch size you can set given the fact your maximum frames in the input were 480000 as explained in previous point.
